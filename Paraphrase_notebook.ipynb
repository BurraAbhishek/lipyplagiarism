{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fa6eb4b",
   "metadata": {},
   "source": [
    "# Paraphrase detection using Machine Learning Techniques\n",
    "\n",
    "#### NOTE: This is the same as the python files in /modules/plagiarism, but due to the absence of efficient Python PDF parsers, the web mining part was not tested fully, and hence, the project as such is non-functional from the UI. However, we have demonstrated 77% accuracy using Random Forest Classifier.\n",
    "\n",
    "### Burra Abhishek (Registration Number: 19BCE1187) \n",
    "### Siddhant Roy (Registration Number: 19BCE1181)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80280442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text pre-processing stage\n",
    "# module modules.plagiarism.preprocessing\n",
    "  \n",
    "from modules.plagiarism.preprocessing import vectorizedocument\n",
    "from modules.plagiarism.preprocessing import parasplitter\n",
    "from modules.plagiarism.preprocessing import removepunctuations\n",
    "from modules.plagiarism.preprocessing import removebullets\n",
    "from modules.plagiarism.preprocessing import tokenizer\n",
    "import re\n",
    "import string\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\" Preprocess a given text \"\"\"\n",
    "    \n",
    "    s = vectorizedocument.text_to_list(text)\n",
    "    t = []\n",
    "    for i in s:\n",
    "        t.append(parasplitter.sbd(i))\n",
    "    t = removepunctuations.removesb(t)\n",
    "    t = removebullets.removebullets(t)\n",
    "    for i in t:\n",
    "        s.append(tokenizer.removeWhiteSpace(i))\n",
    "    return s\n",
    "\n",
    "\n",
    "def preprocessURL(text):\n",
    "    \"\"\" Preprocess a given text from a URL \"\"\"\n",
    "    \n",
    "    s = vectorizedocument.text_to_list(text)\n",
    "    t = []\n",
    "    for i in s:\n",
    "        t.append(parasplitter.sbd(i))\n",
    "    t = removepunctuations.removesb(t)\n",
    "    t = removebullets.removebullets(t)\n",
    "    for i in t:\n",
    "        s.append(tokenizer.removeWhiteSpace(i))\n",
    "    return s\n",
    "\n",
    "\n",
    "def preprocess_train(text):\n",
    "    \"\"\" Preprocess a given text \"\"\"\n",
    "    \n",
    "    s = vectorizedocument.text_to_list_all(text)\n",
    "    t = []\n",
    "    for i in s:\n",
    "        t.append(parasplitter.sbd(i))\n",
    "    t = removepunctuations.removesb(t)\n",
    "    t = removebullets.removebullets(t)\n",
    "    s = []\n",
    "    for i in t:\n",
    "        s.append(tokenizer.removeWhiteSpace(i))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28197982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "import pandas as pd\n",
    "from modules.plagiarism.preprocessing import preprocess\n",
    "from modules.plagiarism.comparisons import ds_splitter\n",
    "from modules.plagiarism.comparisons.classifiers import logistic, randomforest\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def get_train_df(location):\n",
    "    train_file = open(location, mode='r')\n",
    "    unprocessed_train_data = list([example.split(\"\\t\") for example in train_file.readlines()])[1:]\n",
    "    for i in unprocessed_train_data:\n",
    "        i.pop(0)\n",
    "        i[2] = int(i[2].replace(\"\\n\", \"\"))\n",
    "    return unprocessed_train_data\n",
    "\n",
    "\n",
    "def process_dataset(dataset):\n",
    "    for i in dataset:\n",
    "        i[0] = preprocess.preprocess_train(i[0])[0]\n",
    "        i[1] = preprocess.preprocess_train(i[1])[0]\n",
    "    return dataset\n",
    "\n",
    "# PAWS QQP dataset was used to train the models.\n",
    "y = process_dataset(get_train_df('modules/plagiarism/comparisons/datasets/final/train.tsv'))\n",
    "y1 = process_dataset(get_train_df('modules/plagiarism/comparisons/datasets/final/test.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91bdac2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in paris in october 1560 he secretly met the e...</td>\n",
       "      <td>in october 1560 he secretly met with the engli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the nba season of 1975 76 was the 30th season ...</td>\n",
       "      <td>the 1975 76 season of the national basketball ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there are also specific discussions public pro...</td>\n",
       "      <td>there are also public discussions profile spec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when comparable rates of flow can be maintaine...</td>\n",
       "      <td>the results are high when comparable flow rate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it is the seat of zerendi district in akmola r...</td>\n",
       "      <td>it is the seat of the district of zerendi in a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49396</th>\n",
       "      <td>our school is of spiritual and spiritual love ...</td>\n",
       "      <td>our school is of the temporal and the spiritua...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49397</th>\n",
       "      <td>she was in cork on june 24 and arrived on 8 ju...</td>\n",
       "      <td>she was at cork on 24 june and arrived in the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49398</th>\n",
       "      <td>cornelia stuyvesant vanderbilt george and edit...</td>\n",
       "      <td>john john f a cecil the only child of george a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49399</th>\n",
       "      <td>the third season was premiered on 7 june 2010 ...</td>\n",
       "      <td>the fourth season was premiered on june 7 2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49400</th>\n",
       "      <td>it is also from a location on the mainland los...</td>\n",
       "      <td>it is also known from one location on the main...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49401 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  \\\n",
       "0      in paris in october 1560 he secretly met the e...   \n",
       "1      the nba season of 1975 76 was the 30th season ...   \n",
       "2      there are also specific discussions public pro...   \n",
       "3      when comparable rates of flow can be maintaine...   \n",
       "4      it is the seat of zerendi district in akmola r...   \n",
       "...                                                  ...   \n",
       "49396  our school is of spiritual and spiritual love ...   \n",
       "49397  she was in cork on june 24 and arrived on 8 ju...   \n",
       "49398  cornelia stuyvesant vanderbilt george and edit...   \n",
       "49399  the third season was premiered on 7 june 2010 ...   \n",
       "49400  it is also from a location on the mainland los...   \n",
       "\n",
       "                                                       1  2  \n",
       "0      in october 1560 he secretly met with the engli...  0  \n",
       "1      the 1975 76 season of the national basketball ...  1  \n",
       "2      there are also public discussions profile spec...  0  \n",
       "3      the results are high when comparable flow rate...  1  \n",
       "4      it is the seat of the district of zerendi in a...  1  \n",
       "...                                                  ... ..  \n",
       "49396  our school is of the temporal and the spiritua...  0  \n",
       "49397  she was at cork on 24 june and arrived in the ...  1  \n",
       "49398  john john f a cecil the only child of george a...  0  \n",
       "49399     the fourth season was premiered on june 7 2010  0  \n",
       "49400  it is also known from one location on the main...  0  \n",
       "\n",
       "[49401 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4142088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this was a series of nested angular standards ...</td>\n",
       "      <td>this was a series of nested polar scales so th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>his father emigrated to missouri in 1868 but r...</td>\n",
       "      <td>his father emigrated to america in 1868 but re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in january 2011 the deputy secretary general o...</td>\n",
       "      <td>in january 2011 fiba asia deputy secretary gen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>steiner argued that in the right circumstances...</td>\n",
       "      <td>steiner held that the spiritual world can be r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>luciano williames dias born july 25 1970 is a ...</td>\n",
       "      <td>luciano williames dias born 25 july 1970 is a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>the company has branches in tokyo based in the...</td>\n",
       "      <td>the company has branches in tokyo based in sai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>muara teweh abbreviated mtw is a city located ...</td>\n",
       "      <td>teweh abbreviated mtw is a city located in the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>the modern coat of arms of bavaria was designe...</td>\n",
       "      <td>the modern coat of arms of bavaria was designe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>former president brenda kuecks received a clea...</td>\n",
       "      <td>in 2013 former president brenda kuecks receive...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>it is located near point pleasant borough a mu...</td>\n",
       "      <td>it is near point pleasant borough a municipali...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0  \\\n",
       "0     this was a series of nested angular standards ...   \n",
       "1     his father emigrated to missouri in 1868 but r...   \n",
       "2     in january 2011 the deputy secretary general o...   \n",
       "3     steiner argued that in the right circumstances...   \n",
       "4     luciano williames dias born july 25 1970 is a ...   \n",
       "...                                                 ...   \n",
       "7995  the company has branches in tokyo based in the...   \n",
       "7996  muara teweh abbreviated mtw is a city located ...   \n",
       "7997  the modern coat of arms of bavaria was designe...   \n",
       "7998  former president brenda kuecks received a clea...   \n",
       "7999  it is located near point pleasant borough a mu...   \n",
       "\n",
       "                                                      1  2  \n",
       "0     this was a series of nested polar scales so th...  0  \n",
       "1     his father emigrated to america in 1868 but re...  0  \n",
       "2     in january 2011 fiba asia deputy secretary gen...  1  \n",
       "3     steiner held that the spiritual world can be r...  0  \n",
       "4     luciano williames dias born 25 july 1970 is a ...  0  \n",
       "...                                                 ... ..  \n",
       "7995  the company has branches in tokyo based in sai...  1  \n",
       "7996  teweh abbreviated mtw is a city located in the...  0  \n",
       "7997  the modern coat of arms of bavaria was designe...  1  \n",
       "7998  in 2013 former president brenda kuecks receive...  0  \n",
       "7999  it is near point pleasant borough a municipali...  1  \n",
       "\n",
       "[8000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8893af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical analysis\n",
    "\n",
    "# Fuzzy similarity\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "\n",
    "def fuzzysimilarity(dataframe):\n",
    "    \"\"\"\n",
    "    Compares two strings in a Pandas DataFrame: dataframe[0], dataframe[1]\n",
    "    String comparison using Levenshtein distance\n",
    "    to calculate distance between sequences.\n",
    "    We need all ratios\n",
    "    \"\"\"\n",
    "\n",
    "    # Fuzz ratio: similarity of entire string\n",
    "    dataframe['Fuzz Ratio'] = dataframe.apply(lambda x: fuzz.ratio(str(x[0]), str(x[1])), axis=1)\n",
    "\n",
    "    # Fuzz Token Set Ratio: similarity of each token in the string\n",
    "    # The word order does not matter, unlike in fuzz ratio\n",
    "    dataframe['Fuzz Token Set Ratio'] = dataframe.apply(\n",
    "        lambda x: fuzz.token_set_ratio(str(x[0]), str(x[1])), \n",
    "        axis=1\n",
    "        )\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "# N-gram features and Jaccard similarity\n",
    "\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def jaccardDistance(x, y, n):\n",
    "    _w1, _w2, a, b = common_ngrams(x, y, n)\n",
    "    l = len(set(a).union(set(b)))\n",
    "    if l == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return len(set(a).intersection(set(b))) / l\n",
    "\n",
    "\n",
    "def ngrams_ratio(a, b, n):\n",
    "    w1, w2, ngrams1, ngrams2 = common_ngrams(a, b, n)\n",
    "    return len(set(ngrams1).intersection(set(ngrams2))) / (len(w1) + len(w2))\n",
    "\n",
    "\n",
    "def common_ngrams(a, b, n):\n",
    "    # Split the sentences into words\n",
    "    w1 = a.split()\n",
    "    w2 = b.split()\n",
    "    # Get the n grams\n",
    "    ngrams1 = list(ngrams(w1, n))\n",
    "    ngrams2 = list(ngrams(w2, n))\n",
    "    return w1, w2, ngrams1, ngrams2\n",
    "\n",
    "\n",
    "def ngram_features(df):\n",
    "    df['Common Unigram Ratio'] = df.apply(\n",
    "        lambda x: ngrams_ratio(str(x[0]), str(x[1]), 1), \n",
    "        axis=1\n",
    "        )\n",
    "    df['Common Bigram Ratio'] = df.apply(\n",
    "        lambda x: ngrams_ratio(str(x[0]), str(x[1]), 2), \n",
    "        axis=1\n",
    "        )\n",
    "    df['Common Trigram Ratio'] = df.apply(\n",
    "        lambda x: ngrams_ratio(str(x[0]), str(x[1]), 3), \n",
    "        axis=1\n",
    "        )\n",
    "    df['Unigram Jaccard Distance'] = df.apply(\n",
    "        lambda x: jaccardDistance(str(x[0]), str(x[1]), 1), \n",
    "        axis=1\n",
    "        )\n",
    "    df['Bigram Jaccard Distance'] = df.apply(\n",
    "        lambda x: jaccardDistance(str(x[0]), str(x[1]), 2), \n",
    "        axis=1\n",
    "        )\n",
    "    df['Trigram Jaccard Distance'] = df.apply(\n",
    "        lambda x: jaccardDistance(str(x[0]), str(x[1]), 3), \n",
    "        axis=1\n",
    "        )\n",
    "    return df\n",
    "\n",
    "\n",
    "# Normalized Longest Common Subsequence\n",
    "\n",
    "def NLCS(sentence1, sentence2):\n",
    "    \"\"\" Determine the length of the NLCS of two sentences \"\"\"\n",
    "\n",
    "    # Get each individual word from each of the sentences.\n",
    "    word1 = sentence1.split()\n",
    "    word2 = sentence2.split()\n",
    "\n",
    "    # Get the number of words from each sentence.\n",
    "    l1 = len(word1)\n",
    "    l2 = len(word2)\n",
    "\n",
    "    # Initialize the nested list to store all the \n",
    "    # subsequence similarity values\n",
    "    a = []\n",
    "    for i in range(l1 + 1):\n",
    "        l = []\n",
    "        for j in range(l2 + 1):\n",
    "            l.append([])\n",
    "        a.append(l)\n",
    "\n",
    "    for i in range(l1 + 1):\n",
    "        for j in range(l2 + 1):\n",
    "            # Nothing to compare initially\n",
    "            if i == 0 or j == 0:\n",
    "                a[i][j] = 0\n",
    "            # Matching words\n",
    "            # Add 1 to the subsequence\n",
    "            elif word1[i - 1] == word2[j - 1]:\n",
    "                a[i][j] = a[i - 1][j - 1] + 1\n",
    "            # Words do not match\n",
    "            # Get the maximum value of its previous neighbours\n",
    "            else:\n",
    "                a[i][j] = max(a[i-1][j], a[i][j-1])\n",
    "    \n",
    "    # a[l1][l2] contains the length of the \n",
    "    # longest common subsequence of X[0..n-1] & Y[0..m-1] \n",
    "    lf = a[l1][l2]/(len((set(word1).union(set(word2)))))\n",
    "    \n",
    "    # lf is the length of the Normalized longest common subsequence\n",
    "    return lf\n",
    "\n",
    "\n",
    "def apply_nlcs(dataframe):\n",
    "    dataframe[\"Normalized Longest Common Subsequence\"] = dataframe.apply(lambda x: NLCS(x[0], x[1]), axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b729aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Analysis\n",
    "\n",
    "# Normalized Word Mover's Distance\n",
    "\n",
    "from gensim import models\n",
    "\n",
    "# If this code fails, you need to download the GloVe dataset.\n",
    "# Open a file explorer, then go to modules/plagiarism/comparisons/datasets/\n",
    "# Create a new folder \"glove6b\" and go to the following link to download the dataset:\n",
    "# https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
    "# Then use the 50d model. If any other model is used, change the file name accordingly.\n",
    "# Before you can use the model, open a terminal or its equivalent in the same folder, then run\n",
    "# python -m gensim.scripts.glove2word2vec --input  glove.6B.50d.txt --output glove.6B.50d.w2vformat.txt\n",
    "w = models.KeyedVectors.load_word2vec_format(\n",
    "    'modules/plagiarism/comparisons/datasets/glove6b/glove.6B.50d.w2vformat.txt', binary=False)\n",
    "\n",
    "# w.init_sims may throw a deprecation warning, use fill_norms instead.\n",
    "#w.init_sims(replace=True)\n",
    "w.fill_norms()\n",
    "\n",
    "def nwmd(dataframe):\n",
    "    dataframe[\"Normalized Word Mover's Distance\"] = dataframe.apply(\n",
    "        lambda x: w.wmdistance(x[0], x[1]), \n",
    "        axis=1\n",
    "        )\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a95cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply these features to the dataset\n",
    "def get_features(data_list):\n",
    "    x = pd.DataFrame(data_list)\n",
    "    x = (apply_nlcs(fuzzysimilarity(x)))\n",
    "    x = (ngram_features(x))\n",
    "    x = (nwmd(x))\n",
    "    #x = (generateoverlaps.syntactics(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd8c73d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X - Y split and scaling\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def x_y_split(df):\n",
    "    Y = pd.DataFrame(df[2])\n",
    "    df.drop(2, inplace=True, axis=1)\n",
    "    return df, Y\n",
    "\n",
    "\n",
    "def preprocess_ds(df):\n",
    "    df.drop(1, inplace=True, axis=1)\n",
    "    df.drop(0, inplace=True, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def scale_df(df):\n",
    "    scaler = StandardScaler()\n",
    "    v = df.values.tolist()\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(v))\n",
    "    return df_scaled\n",
    "\n",
    "\n",
    "def dsSplitter(l):\n",
    "    x = get_features(l)\n",
    "\n",
    "    # At this stage we have our dataset\n",
    "    x = preprocess_ds(x)\n",
    "\n",
    "    # Scaling the dataset\n",
    "    X, Y = x_y_split(x)\n",
    "    X = pd.DataFrame(scale_df(X))\n",
    "    y = Y.values.tolist()\n",
    "    Y = []\n",
    "    for i in y:\n",
    "        Y.append(i[0])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6789cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = dsSplitter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a2fa57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.249096</td>\n",
       "      <td>-0.202392</td>\n",
       "      <td>-0.368471</td>\n",
       "      <td>0.154474</td>\n",
       "      <td>-0.021533</td>\n",
       "      <td>0.108093</td>\n",
       "      <td>-0.268702</td>\n",
       "      <td>-0.291004</td>\n",
       "      <td>-0.145425</td>\n",
       "      <td>-0.315959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.273308</td>\n",
       "      <td>0.554983</td>\n",
       "      <td>-0.069904</td>\n",
       "      <td>-1.065134</td>\n",
       "      <td>0.013835</td>\n",
       "      <td>-0.045936</td>\n",
       "      <td>1.100659</td>\n",
       "      <td>0.419766</td>\n",
       "      <td>-0.067558</td>\n",
       "      <td>-0.369964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.391916</td>\n",
       "      <td>0.554983</td>\n",
       "      <td>-0.163206</td>\n",
       "      <td>-0.049709</td>\n",
       "      <td>-1.292382</td>\n",
       "      <td>-1.509848</td>\n",
       "      <td>0.244808</td>\n",
       "      <td>-1.238698</td>\n",
       "      <td>-1.292003</td>\n",
       "      <td>0.663582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.834194</td>\n",
       "      <td>0.554983</td>\n",
       "      <td>-1.702688</td>\n",
       "      <td>1.244928</td>\n",
       "      <td>-0.831929</td>\n",
       "      <td>-1.080914</td>\n",
       "      <td>0.387450</td>\n",
       "      <td>-0.859620</td>\n",
       "      <td>-0.977619</td>\n",
       "      <td>-0.326633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.088843</td>\n",
       "      <td>0.554983</td>\n",
       "      <td>0.349954</td>\n",
       "      <td>0.801053</td>\n",
       "      <td>-0.046452</td>\n",
       "      <td>-0.523299</td>\n",
       "      <td>1.100659</td>\n",
       "      <td>-0.072306</td>\n",
       "      <td>-0.483586</td>\n",
       "      <td>0.336392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49396</th>\n",
       "      <td>0.249096</td>\n",
       "      <td>0.554983</td>\n",
       "      <td>1.257854</td>\n",
       "      <td>-1.289390</td>\n",
       "      <td>-0.883005</td>\n",
       "      <td>-0.636047</td>\n",
       "      <td>0.442312</td>\n",
       "      <td>-0.909065</td>\n",
       "      <td>-0.713536</td>\n",
       "      <td>0.604907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49397</th>\n",
       "      <td>-0.552169</td>\n",
       "      <td>0.554983</td>\n",
       "      <td>-0.603058</td>\n",
       "      <td>0.404031</td>\n",
       "      <td>-1.209320</td>\n",
       "      <td>-1.772928</td>\n",
       "      <td>0.489337</td>\n",
       "      <td>-1.238698</td>\n",
       "      <td>-1.501593</td>\n",
       "      <td>-0.148548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49398</th>\n",
       "      <td>-1.353435</td>\n",
       "      <td>0.302525</td>\n",
       "      <td>-1.469433</td>\n",
       "      <td>-0.366659</td>\n",
       "      <td>-0.644987</td>\n",
       "      <td>-1.432472</td>\n",
       "      <td>0.322613</td>\n",
       "      <td>-0.859620</td>\n",
       "      <td>-1.321945</td>\n",
       "      <td>0.164255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49399</th>\n",
       "      <td>-2.635460</td>\n",
       "      <td>0.554983</td>\n",
       "      <td>-2.272866</td>\n",
       "      <td>-2.272667</td>\n",
       "      <td>-2.196686</td>\n",
       "      <td>-1.096134</td>\n",
       "      <td>-3.178594</td>\n",
       "      <td>-1.897963</td>\n",
       "      <td>-1.045963</td>\n",
       "      <td>2.570832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49400</th>\n",
       "      <td>-0.071410</td>\n",
       "      <td>0.302525</td>\n",
       "      <td>-0.518471</td>\n",
       "      <td>0.415802</td>\n",
       "      <td>-0.269779</td>\n",
       "      <td>-0.244087</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>-0.458244</td>\n",
       "      <td>-0.464676</td>\n",
       "      <td>-0.017053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49401 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.249096 -0.202392 -0.368471  0.154474 -0.021533  0.108093 -0.268702   \n",
       "1     -1.273308  0.554983 -0.069904 -1.065134  0.013835 -0.045936  1.100659   \n",
       "2     -0.391916  0.554983 -0.163206 -0.049709 -1.292382 -1.509848  0.244808   \n",
       "3     -1.834194  0.554983 -1.702688  1.244928 -0.831929 -1.080914  0.387450   \n",
       "4      0.088843  0.554983  0.349954  0.801053 -0.046452 -0.523299  1.100659   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "49396  0.249096  0.554983  1.257854 -1.289390 -0.883005 -0.636047  0.442312   \n",
       "49397 -0.552169  0.554983 -0.603058  0.404031 -1.209320 -1.772928  0.489337   \n",
       "49398 -1.353435  0.302525 -1.469433 -0.366659 -0.644987 -1.432472  0.322613   \n",
       "49399 -2.635460  0.554983 -2.272866 -2.272667 -2.196686 -1.096134 -3.178594   \n",
       "49400 -0.071410  0.302525 -0.518471  0.415802 -0.269779 -0.244087  0.113139   \n",
       "\n",
       "              7         8         9  \n",
       "0     -0.291004 -0.145425 -0.315959  \n",
       "1      0.419766 -0.067558 -0.369964  \n",
       "2     -1.238698 -1.292003  0.663582  \n",
       "3     -0.859620 -0.977619 -0.326633  \n",
       "4     -0.072306 -0.483586  0.336392  \n",
       "...         ...       ...       ...  \n",
       "49396 -0.909065 -0.713536  0.604907  \n",
       "49397 -1.238698 -1.501593 -0.148548  \n",
       "49398 -0.859620 -1.321945  0.164255  \n",
       "49399 -1.897963 -1.045963  2.570832  \n",
       "49400 -0.458244 -0.464676 -0.017053  \n",
       "\n",
       "[49401 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67127dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, Y1 = dsSplitter(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "091bdb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The machine learning part\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def train_lr(Xtrain, Ytrain):\n",
    "    lrModel = LogisticRegression(max_iter=10000)\n",
    "    lrModel.fit(Xtrain, Ytrain)\n",
    "    return lrModel\n",
    "\n",
    "\n",
    "def rfModel(Xtrain, Ytrain):\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(Xtrain, Ytrain)\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b0d87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual training part, where the models are trained using the training data\n",
    "\n",
    "lrModel = train_lr(X, Y)\n",
    "rfModel = rfModel(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42c5b66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy:  0.7215\n",
      "Logistic Regression Precision:  0.7235133287764867\n",
      "Logistic Regression Recall:  0.5986990950226244\n",
      "Logistic Regression F1 score:  0.6552151036830702\n",
      " \n",
      "Random Forest Accuracy:  0.768625\n",
      "Random Forest Precision:  0.7858839497794368\n",
      "Random Forest Recall:  0.6549773755656109\n",
      "Random Forest F1 score:  0.7144840351689032\n"
     ]
    }
   ],
   "source": [
    "Y2 = lrModel.predict(pd.DataFrame(X1))\n",
    "\n",
    "Y3 = rfModel.predict(pd.DataFrame(X1))\n",
    "\n",
    "X2 = X1.values.tolist()\n",
    "for i in range(0, len(y1)):\n",
    "    # Obvious lazy plagiarism is sometimes missed.\n",
    "    if y1[i][0] == y1[i][1]:\n",
    "        Y2[i] = 1\n",
    "        Y3[i] = 1\n",
    "\n",
    "print(\"Logistic Regression Accuracy: \", metrics.accuracy_score(Y1, Y2))\n",
    "print(\"Logistic Regression Precision: \", metrics.precision_score(Y1, Y2))\n",
    "print(\"Logistic Regression Recall: \", metrics.recall_score(Y1, Y2))\n",
    "print(\"Logistic Regression F1 score: \", metrics.f1_score(Y1, Y2))\n",
    "print(\" \")\n",
    "print(\"Random Forest Accuracy: \", metrics.accuracy_score(Y1, Y3))\n",
    "print(\"Random Forest Precision: \", metrics.precision_score(Y1, Y3))\n",
    "print(\"Random Forest Recall: \", metrics.recall_score(Y1, Y3))\n",
    "print(\"Random Forest F1 score: \", metrics.f1_score(Y1, Y3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
