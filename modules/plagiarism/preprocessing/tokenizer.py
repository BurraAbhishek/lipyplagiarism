from nltk.tokenize import word_tokenize

def tokenize(sentence):
    return word_tokenize(sentence)